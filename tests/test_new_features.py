#!/usr/bin/env python3
"""
Test script for new collaboration features
"""

import sys
from pathlib import Path

# Add src directory to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from src.core.ai_client_manager import AIClientManager
from src.config.config_manager import ConfigManager
from src.models.data_models import Message


def test_new_features():
    """Test the new multi-round and streaming features."""
    print("ğŸ§ª TESTING NEW COLLABORATION FEATURES")
    print("=" * 50)
    
    config = ConfigManager()
    manager = AIClientManager(config)
    
    # Test message
    messages = [Message(
        conversation_id="feature_test",
        participant="user",
        content="Explain the benefits of containerization in software deployment"
    )]
    
    print(f"ğŸ“ Test Query: {messages[0].content}")
    print()
    
    # Test 1: Verify methods exist
    print("âœ… Feature Availability Check:")
    features = [
        ('get_smart_responses', 'Basic smart responses'),
        ('get_collaborative_responses', 'Multi-round collaboration'),
        ('get_streaming_responses', 'Async streaming'),
        ('get_streaming_responses_sync', 'Sync streaming'),
        ('_should_continue_iteration', 'Iteration logic'),
        ('_calculate_response_similarity', 'Response similarity')
    ]
    
    for method_name, description in features:
        if hasattr(manager, method_name):
            print(f"  âœ… {description}: Available")
        else:
            print(f"  âŒ {description}: Missing")
    
    print()
    
    # Test 2: Response coordinator enhancements
    print("âœ… Response Coordinator Features:")
    coordinator = manager.response_coordinator
    
    coordinator_features = [
        ('coordinate_responses', 'Provider coordination'),
        ('detect_chaining_cue', 'AI-to-AI chaining'),
        ('_calculate_semantic_relevance', 'Semantic relevance scoring'),
        ('_add_collaboration_context', 'Collaboration context')
    ]
    
    for method_name, description in coordinator_features:
        if hasattr(coordinator, method_name):
            print(f"  âœ… {description}: Available")
        else:
            print(f"  âŒ {description}: Missing")
    
    print()
    
    # Test 3: Configuration checks
    print("âœ… System Configuration:")
    available_providers = manager.get_available_providers()
    print(f"  ğŸ“¡ Available providers: {available_providers}")
    
    health = manager.get_provider_health()
    for provider, status in health.items():
        print(f"  ğŸ¥ {provider}: {status['status']} (failures: {status['failure_count']})")
    
    print()
    
    # Test 4: Mock collaboration test
    print("âœ… Mock Collaboration Test:")
    try:
        # Test provider selection
        responding_providers = coordinator.coordinate_responses(
            messages[0], [], available_providers
        )
        print(f"  ğŸ¯ Selected providers: {responding_providers}")
        
        # Test relevance calculation
        for provider in available_providers:
            relevance = coordinator._calculate_semantic_relevance(messages[0], provider, [])
            print(f"  ğŸ“Š {provider} relevance: {relevance:.2f}")
        
        # Test mention detection
        mention_msg = Message(
            conversation_id="test",
            participant="user", 
            content="@openai what do you think about this?"
        )
        
        mention_providers = coordinator.coordinate_responses(
            mention_msg, [], available_providers
        )
        print(f"  ğŸ’¬ Mention routing: {mention_providers}")
        
    except Exception as e:
        print(f"  âš ï¸ Mock test error: {str(e)}")
    
    print()
    print("ğŸ‰ NEW FEATURES TEST COMPLETED!")
    print("âœ¨ All advanced collaboration features are properly integrated")
    print("ğŸ“š See docs/COMPREHENSIVE_DOCUMENTATION.md for usage examples")


if __name__ == "__main__":
    test_new_features()
